{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "istic_m2_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEkD+LLMAwfXY8Tq3YJzwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumabkargit/intro-to-machine-learning/blob/master/istic_m2_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcaxjFeEvcRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5785ce31-1b01-4ca1-bdba-1b268b5b3eea"
      },
      "source": [
        "!pip install pandas_ods_reader\n",
        "\n",
        "import tensorflow as tf\n",
        "from pandas_ods_reader import read_ods\n",
        "import shutil\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "print(tf.__version__)\n",
        "\n",
        "# Authentification Google\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download du fichier\n",
        "id = '1QI-6i1pQgyXpGZPWKKYKdKHIX9nGvkN0'\n",
        "downloaded = drive.CreateFile({'id': '1QI-6i1pQgyXpGZPWKKYKdKHIX9nGvkN0'})\n",
        "downloaded.GetContentFile('subjective_test_scores.ods')\n",
        "\n",
        "# Path of the file to read\n",
        "data = 'subjective_test_scores.ods'\n",
        "\n",
        "# load a sheet based on its index (1 based)\n",
        "sheet_idx = 1\n",
        "df_all_data = read_ods(data, sheet_idx, columns=['QP', 'Davg', 'Dmax', 'N' , 'MOS'])\n",
        "df_train = df_all_data[1:81]\n",
        "df_valid = df_all_data[82:98]\n",
        "df_test = df_all_data[99:116]\n",
        "\n",
        "CSV_COLUMN_NAMES = list(df_all_data)\n",
        "print(CSV_COLUMN_NAMES)\n",
        "\n",
        "FEATURE_NAMES = CSV_COLUMN_NAMES[0:3] # \n",
        "LABEL_NAME = CSV_COLUMN_NAMES[4] #\n",
        "\n",
        "#Create feature columns\n",
        "\n",
        "feature_columns = [tf.feature_column.numeric_column(key = k) for k in FEATURE_NAMES]\n",
        "\n",
        "#Define input function\n",
        "\n",
        "def train_input_fn(df, batch_size = 128):\n",
        "    #1. Convert dataframe into correct (features,label) format for Estimator API\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tensors = (dict(df[FEATURE_NAMES]), df[LABEL_NAME]))\n",
        "    \n",
        "    # Note:\n",
        "    # If we returned now, the Dataset would iterate over the data once  \n",
        "    # in a fixed order, and only produce a single element at a time.\n",
        "    \n",
        "    #2. Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(buffer_size = 1000).repeat(count = None).batch(batch_size = batch_size)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def eval_input_fn(df, batch_size = 128):\n",
        "    #1. Convert dataframe into correct (features,label) format for Estimator API\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tensors = (dict(df[FEATURE_NAMES]), df[LABEL_NAME]))\n",
        "    \n",
        "    #2.Batch the examples.\n",
        "    dataset = dataset.batch(batch_size = batch_size)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def predict_input_fn(df, batch_size = 128):\n",
        "    #1. Convert dataframe into correct (features) format for Estimator API\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tensors = dict(df[FEATURE_NAMES])) # no label\n",
        "\n",
        "    #2.Batch the examples.\n",
        "    dataset = dataset.batch(batch_size = batch_size)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "#Choose Estimator\n",
        "OUTDIR = \"QoS\"\n",
        "\n",
        "model = tf.estimator.LinearRegressor(\n",
        "    feature_columns = feature_columns,\n",
        "    model_dir = OUTDIR,\n",
        "    config = tf.estimator.RunConfig(tf_random_seed = 1) # for reproducibility\n",
        ")\n",
        "\n",
        "#Train\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO) # so loss is printed during training\n",
        "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
        "\n",
        "model.train(\n",
        "    input_fn = lambda: train_input_fn(df = df_train), \n",
        "    steps = 500)\n",
        "\n",
        "def print_rmse(model, df):\n",
        "    metrics = model.evaluate(input_fn = lambda: eval_input_fn(df))\n",
        "    print(\"RMSE on dataset = {}\".format(metrics[\"average_loss\"]**.5))\n",
        "print_rmse(model = model, df = df_valid)\n",
        "\n",
        "#Predict\n",
        "predictions = model.predict(input_fn = lambda: predict_input_fn(df = df_test))\n",
        "for items in predictions:\n",
        "    print(items)\n",
        "\n",
        "\n",
        "#Change Estimator type\n",
        "\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "shutil.rmtree(path = OUTDIR, ignore_errors = True) \n",
        "model = tf.estimator.DNNRegressor(\n",
        "    hidden_units = [10,10], # specify neural architecture\n",
        "    feature_columns = feature_columns, \n",
        "    model_dir = OUTDIR,\n",
        "    config = tf.estimator.RunConfig(tf_random_seed = 1)\n",
        ")\n",
        "model.train(\n",
        "    input_fn = lambda: train_input_fn(df = df_train), \n",
        "    steps = 500)\n",
        "print_rmse(model = model, df = df_valid)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_ods_reader in /usr/local/lib/python3.6/dist-packages (0.0.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_ods_reader) (4.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pandas_ods_reader) (0.25.3)\n",
            "Requirement already satisfied: ezodf in /usr/local/lib/python3.6/dist-packages (from pandas_ods_reader) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas_ods_reader) (1.17.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas_ods_reader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas_ods_reader) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->pandas_ods_reader) (1.12.0)\n",
            "1.15.0\n",
            "['QP', 'Davg', 'Dmax', 'N', 'MOS']\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4e2b89b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:loss = 7415.175, step = 1\n",
            "INFO:tensorflow:global_step/sec: 530.913\n",
            "INFO:tensorflow:loss = 903.8495, step = 101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.578\n",
            "INFO:tensorflow:loss = 814.8701, step = 201 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.333\n",
            "INFO:tensorflow:loss = 849.97815, step = 301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.838\n",
            "INFO:tensorflow:loss = 861.99915, step = 401 (0.141 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 608.00146.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-01-16T12:01:05Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-01-16-12:01:06\n",
            "INFO:tensorflow:Saving dict for global step 500: average_loss = 2.3809524, global_step = 500, label/mean = 5.5776873, loss = 38.095238, prediction/mean = 5.6166453\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: taxi_trained/model.ckpt-500\n",
            "RMSE on dataset = 1.5430334922631619\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "{'predictions': array([12.7490015], dtype=float32)}\n",
            "{'predictions': array([1.8177607], dtype=float32)}\n",
            "{'predictions': array([2.0897567], dtype=float32)}\n",
            "{'predictions': array([2.0897567], dtype=float32)}\n",
            "{'predictions': array([2.305091], dtype=float32)}\n",
            "{'predictions': array([3.858789], dtype=float32)}\n",
            "{'predictions': array([2.7357593], dtype=float32)}\n",
            "{'predictions': array([2.7357593], dtype=float32)}\n",
            "{'predictions': array([5.8368936], dtype=float32)}\n",
            "{'predictions': array([14.559061], dtype=float32)}\n",
            "{'predictions': array([1.8744226], dtype=float32)}\n",
            "{'predictions': array([2.5429134], dtype=float32)}\n",
            "{'predictions': array([4.1511416], dtype=float32)}\n",
            "{'predictions': array([4.0279922], dtype=float32)}\n",
            "{'predictions': array([11.94652], dtype=float32)}\n",
            "{'predictions': array([13.864947], dtype=float32)}\n",
            "{'predictions': array([2.0444083], dtype=float32)}\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe4f8c754e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:loss = 3355.893, step = 1\n",
            "INFO:tensorflow:global_step/sec: 523.894\n",
            "INFO:tensorflow:loss = 930.215, step = 101 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 731.13\n",
            "INFO:tensorflow:loss = 819.96826, step = 201 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.734\n",
            "INFO:tensorflow:loss = 849.48376, step = 301 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.078\n",
            "INFO:tensorflow:loss = 863.50305, step = 401 (0.135 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 638.7498.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-01-16T12:01:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-01-16-12:01:08\n",
            "INFO:tensorflow:Saving dict for global step 500: average_loss = 2.8459356, global_step = 500, label/mean = 5.5776873, loss = 45.53497, prediction/mean = 5.329455\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: taxi_trained/model.ckpt-500\n",
            "RMSE on dataset = 1.686990095736968\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}