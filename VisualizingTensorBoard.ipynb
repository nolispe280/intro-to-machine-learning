{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumabkargit/intro-to-machine-learning/blob/master/VisualizingTensorBoard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXG5bHB_Q6aY",
        "colab_type": "code",
        "outputId": "b815097c-0b3b-43ab-8747-a90046e2a16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "!pip install tf-nightly\n",
        "\n",
        "# import packages\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorboard import notebook\n",
        "\n",
        " # View open TensorBoard instances\n",
        "\n",
        "notebook.list()\n",
        "\n",
        "# Control TensorBoard display. If no port is provided, \n",
        "# the most recently launched TensorBoard is used\n",
        "notebook.display(port=6006, height=1000) \n",
        "\n",
        "# load dataset and split in train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# standardize the dataset\n",
        "scaler_X_train = StandardScaler().fit(X_train)\n",
        "scaler_X_test = StandardScaler().fit(X_test)\n",
        "X_train = scaler_X_train.transform(X_train)\n",
        "X_test = scaler_X_test.transform(X_test)\n",
        "\n",
        "# reshape y-data to become column vector\n",
        "y_train = np.reshape(y_train, [-1, 1])\n",
        "y_test = np.reshape(y_test, [-1, 1])\n",
        "\n",
        "# build the linear model\n",
        "class LinearRegressionModel(Model):\n",
        "  def __init__(self):\n",
        "    super(LinearRegressionModel, self).__init__()\n",
        "    # initialize weight and bias variables\n",
        "    self.weight = tf.Variable(\n",
        "        initial_value = tf. random.normal(\n",
        "            [13, 1], dtype=tf.float64),\n",
        "        trainable=True)\n",
        "    self.bias = tf.Variable(initial_value = tf.constant(\n",
        "        1.0, shape=[], dtype=tf.float64), trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.add(tf.matmul(inputs, self.weight), self.bias)\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "# parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "# use tf.data to batch and shuffle the dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_train, y_train)).shuffle(len(X_train)).batch(batch_size)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
        "\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_rmse = tf.keras.metrics.RootMeanSquaredError(name='train_rmse')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_rmse = tf.keras.metrics.RootMeanSquaredError(name='test_rmse')\n",
        "\n",
        "# use tf.GradientTape to train the model\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_rmse(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(inputs, labels):\n",
        "  predictions = model(inputs)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_rmse(labels, predictions)\n",
        "\n",
        "  # Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# set up summary writers to write the summaries to disk in a different logs directory\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for train_inputs, train_labels in train_ds:\n",
        "    train_step(train_inputs, train_labels)\n",
        "  with train_summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('rmse', train_rmse.result(), step=epoch)\n",
        "\n",
        "  for test_inputs, test_labels in test_ds:\n",
        "    test_step(test_inputs, test_labels)\n",
        "  with test_summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('rmse', test_rmse.result(), step=epoch)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, RMSE: {}, Test Loss: {}, Test RMSE: {}'\n",
        "\n",
        "  if ((epoch+1) % 100 == 0):\n",
        "    print (template.format(epoch+1,\n",
        "                           train_loss.result(),\n",
        "                           train_rmse.result(),\n",
        "                           test_loss.result(),\n",
        "                           test_rmse.result()))\n",
        "    \n",
        "  # Reset metrics every epoch\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  train_rmse.reset_states()\n",
        "  test_rmse.reset_states()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/f1/824a7639de4a0772eb824ef3cdd141cfbdd62ae7a77d7637467edd8779c1/tf_nightly-2.1.0.dev20191116-cp36-cp36m-manylinux2010_x86_64.whl (402.8MB)\n",
            "\u001b[K     |████████████████████████████████| 402.8MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.2)\n",
            "Requirement already satisfied: tb-nightly<2.2.0a0,>=2.1.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.1.0a20191116)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tf-nightly) (41.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (1.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly) (3.1.0)\n",
            "Installing collected packages: tf-nightly\n",
            "Successfully installed tf-nightly-2.1.0.dev20191116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "No known TensorBoard instances running.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 1000));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 100, Loss: 22.037517547607422, RMSE: 4.724170207977295, Test Loss: 29.118572235107422, Test RMSE: 4.610310077667236\n",
            "Epoch 200, Loss: 22.01976776123047, RMSE: 4.722591400146484, Test Loss: 29.16248321533203, Test RMSE: 4.618571758270264\n",
            "Epoch 300, Loss: 22.01911163330078, RMSE: 4.722567558288574, Test Loss: 29.1754150390625, Test RMSE: 4.620066165924072\n",
            "Epoch 400, Loss: 22.019094467163086, RMSE: 4.722574234008789, Test Loss: 29.178226470947266, Test RMSE: 4.6203837394714355\n",
            "Epoch 500, Loss: 22.019094467163086, RMSE: 4.722576141357422, Test Loss: 29.178810119628906, Test RMSE: 4.620449066162109\n",
            "Epoch 600, Loss: 22.01909637451172, RMSE: 4.722577095031738, Test Loss: 29.17892837524414, Test RMSE: 4.620462417602539\n",
            "Epoch 700, Loss: 22.01909637451172, RMSE: 4.72257661819458, Test Loss: 29.178953170776367, Test RMSE: 4.620465278625488\n",
            "Epoch 800, Loss: 22.01909637451172, RMSE: 4.72257661819458, Test Loss: 29.178958892822266, Test RMSE: 4.6204657554626465\n",
            "Epoch 900, Loss: 22.01909637451172, RMSE: 4.72257661819458, Test Loss: 29.178958892822266, Test RMSE: 4.620466232299805\n",
            "Epoch 1000, Loss: 22.01909637451172, RMSE: 4.72257661819458, Test Loss: 29.178958892822266, Test RMSE: 4.620466232299805\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}